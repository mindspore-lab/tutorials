{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620b1bb9-d188-4916-8a88-392b301e78dd",
   "metadata": {},
   "source": [
    "## mindspore.ops.cumsum(x, axis, dtype=None) -〉 Tensor\n",
    "- 输入：\n",
    "    * x必须为mindspore的tensor。\n",
    "    * axis必须为int类型。\n",
    "    * dtype必须为mindspore.dtype类型。\n",
    "- 返回：mindspore的tensor, shape与input一样。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e75cf-6761-4880-9880-b5add98b36ac",
   "metadata": {},
   "source": [
    "此接口的输入参数使用x，与其他cum系列（使用input）接口不一致，建议统一。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "518c829d-80a5-4d98-b90c-09635ae35665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mindspore output ->\n",
      " [[ 3  4  6 10]\n",
      " [ 4 10 13 19]\n",
      " [ 8 13 21 26]\n",
      " [ 9 16 28 35]]\n",
      "\n",
      "\n",
      "torch     output ->\n",
      " tensor([[ 3,  4,  6, 10],\n",
      "        [ 4, 10, 13, 19],\n",
      "        [ 8, 13, 21, 26],\n",
      "        [ 9, 16, 28, 35]])\n",
      "\n",
      "\n",
      "jax       output ->\n",
      " [[ 3  4  6 10]\n",
      " [ 4 10 13 19]\n",
      " [ 8 13 21 26]\n",
      " [ 9 16 28 35]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mindspore as ms\n",
    "import torch\n",
    "import jax.numpy as jnp\n",
    "\n",
    "input = np.array([[3, 4, 6, 10], [1, 6, 7, 9], [4, 3, 8, 7], [1, 3, 7, 9]])\n",
    "\n",
    "y1 = ms.ops.cumsum(ms.tensor(input), axis = 0)\n",
    "y2 = torch.cumsum(torch.tensor(input), dim = 0)\n",
    "y3 = jnp.cumsum(input, axis = 0)\n",
    "print ('mindspore output ->\\n',y1)\n",
    "print('\\n')\n",
    "print ('torch     output ->\\n',y2)\n",
    "print('\\n')\n",
    "print ('jax       output ->\\n',y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00564cac-e16c-4328-a4a4-a16a61f5053a",
   "metadata": {},
   "source": [
    "ms和jax不会输出类型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fe9f4e0-90af-4528-a8c1-0d35a867a339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch     output ->\n",
      " tensor([[ 3.,  4.,  6., 10.],\n",
      "        [ 4., 10., 13., 19.],\n",
      "        [ 8., 13., 21., 26.],\n",
      "        [ 9., 16., 28., 35.]])\n"
     ]
    }
   ],
   "source": [
    "out2 = torch.tensor([])\n",
    "\n",
    "torch.cumsum(torch.tensor(input), dim = 0, out = out2)\n",
    "print ('torch     output ->\\n',out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b258b498-7633-4d9d-b687-90267987b16b",
   "metadata": {},
   "source": [
    "torch还提供了出参的方式，ms未支持。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fcbe1fa-7af2-4f85-9c27-c318cb2e7017",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Failed calling CumSum with \"CumSum(exclusive=bool, reverse=bool)(input=<class 'numpy.ndarray'>, axis=int)\".\nThe valid calling should be: \n\"CumSum(exclusive=<bool>, reverse=<bool>)(input=<Tensor>, axis=<int>)\".\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/ccsrc/pipeline/pynative/pynative_utils.cc:1294 PrintTypeCastError\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y1 \u001b[38;5;241m=\u001b[39m \u001b[43mms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/function/math_func.py:5651\u001b[0m, in \u001b[0;36mcumsum\u001b[0;34m(x, axis, dtype)\u001b[0m\n\u001b[1;32m   5649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m dtype:\n\u001b[1;32m   5650\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m-> 5651\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcumsum_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/auto_generate/gen_ops_prim.py:3997\u001b[0m, in \u001b[0;36mCumSum.__call__\u001b[0;34m(self, input, axis)\u001b[0m\n\u001b[1;32m   3996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, axis):\n\u001b[0;32m-> 3997\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclusive\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreverse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/primitive.py:405\u001b[0m, in \u001b[0;36mPrimitive.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_elim:\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m--> 405\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/ops/primitive.py:1022\u001b[0m, in \u001b[0;36m_run_op\u001b[0;34m(obj, op_name, args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Single op execution function supported by ge in PyNative mode.\"\"\"\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _RunOpHook\u001b[38;5;241m.\u001b[39mcurrent:\n\u001b[0;32m-> 1022\u001b[0m     stub \u001b[38;5;241m=\u001b[39m \u001b[43m_pynative_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_op_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_stub(stub)\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _RunOpHook\u001b[38;5;241m.\u001b[39mcurrent\u001b[38;5;241m.\u001b[39mhook(obj, args)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/mindspore/common/api.py:1423\u001b[0m, in \u001b[0;36m_PyNativeExecutor.run_op_async\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_op_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m   1414\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;124;03m    Run single op async.\u001b[39;00m\n\u001b[1;32m   1416\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;124;03m        StubNode, result of run op.\u001b[39;00m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_op_async\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Failed calling CumSum with \"CumSum(exclusive=bool, reverse=bool)(input=<class 'numpy.ndarray'>, axis=int)\".\nThe valid calling should be: \n\"CumSum(exclusive=<bool>, reverse=<bool>)(input=<Tensor>, axis=<int>)\".\n\n----------------------------------------------------\n- C++ Call Stack: (For framework developers)\n----------------------------------------------------\nmindspore/ccsrc/pipeline/pynative/pynative_utils.cc:1294 PrintTypeCastError\n"
     ]
    }
   ],
   "source": [
    "y1 = ms.ops.cumsum(input, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1050b2d7-b6e4-4cce-90ed-9797c0dba5e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cumprod() received an invalid combination of arguments - got (numpy.ndarray, dim=int), but expected one of:\n * (Tensor input, int dim, *, torch.dtype dtype, Tensor out)\n * (Tensor input, name dim, *, torch.dtype dtype, Tensor out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumprod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: cumprod() received an invalid combination of arguments - got (numpy.ndarray, dim=int), but expected one of:\n * (Tensor input, int dim, *, torch.dtype dtype, Tensor out)\n * (Tensor input, name dim, *, torch.dtype dtype, Tensor out)\n"
     ]
    }
   ],
   "source": [
    "y2 = torch.cumprod(input, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1701d368-1e09-40f9-833e-122dcf6446d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot interpret 'torch.int64' as a data type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y3 \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcumprod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/jax/_src/numpy/reductions.py:685\u001b[0m, in \u001b[0;36m_make_cumulative_reduction.<locals>.cumulative_reduction\u001b[0;34m(a, axis, dtype, out)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;129m@implements\u001b[39m(np_reduction, skip_params\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    682\u001b[0m         lax_description\u001b[38;5;241m=\u001b[39mCUML_REDUCTION_LAX_DESCRIPTION)\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcumulative_reduction\u001b[39m(a: ArrayLike, axis: Axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    684\u001b[0m                          dtype: DTypeLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, out: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Array:\n\u001b[0;32m--> 685\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_cumulative_reduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_ensure_optional_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 8 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/mindspore/lib/python3.9/site-packages/jax/_src/dtypes.py:347\u001b[0m, in \u001b[0;36missubdtype\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns True if first argument is a typecode lower/equal in type hierarchy.\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03mThis is like :func:`numpy.issubdtype`, but can handle dtype extensions such as\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m:obj:`jax.dtypes.bfloat16` and `jax.dtypes.prng_key`.\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# Main departures from np.issubdtype are:\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# - \"extended\" dtypes (like prng key types) are not normal numpy dtypes, so we\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m#   need to handle them specifically. However, their scalar types do conform to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# unhashable (e.g. custom objects with a dtype attribute). The following check is\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# fast and covers the majority of calls to this function within JAX library code.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _issubdtype_cached(\n\u001b[0;32m--> 347\u001b[0m   a \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, (\u001b[38;5;28mtype\u001b[39m, np\u001b[38;5;241m.\u001b[39mdtype, ExtendedDType)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    348\u001b[0m   b \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(b, (\u001b[38;5;28mtype\u001b[39m, np\u001b[38;5;241m.\u001b[39mdtype, ExtendedDType)) \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdtype(b),  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    349\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot interpret 'torch.int64' as a data type"
     ]
    }
   ],
   "source": [
    "y3 = jnp.cumprod(torch.tensor(input), axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59517714-1ef1-43d2-ac0e-7b84d4ab1c65",
   "metadata": {},
   "source": [
    "当输入类型不正确时，报错信息torch最简洁明确。建议ms优化。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
